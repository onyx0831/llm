{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "asset_list = glob('/media/sj-archimedes/data/masaya_kondo/research/mllm/box_asset/list/*.pkl')\n",
    "asset_list_df = pd.concat([pd.read_pickle(path) for path in asset_list])\n",
    "asset_img_dir = '/media/sj-archimedes/data/masaya_kondo/research/mllm/box_asset/images'\n",
    "\n",
    "# epsファイルは検証から除外している\n",
    "asset_list_df['ext'] = asset_list_df['name'].map(lambda x: x.split('.')[-1])\n",
    "asset_list_df = asset_list_df[~asset_list_df['ext'].map(lambda x: 'eps' == x)]\n",
    "asset_list_df['box_symbol'] = asset_list_df['box_path'].map(lambda x: x.split('/')[2])\n",
    "asset_list_df['local_path'] = asset_list_df[['box_symbol', 'box_id', 'ext']].apply(lambda x: f'{asset_img_dir}/{x[0]}/{x[1]}.{x[2]}', axis=1)\n",
    "asset_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/media/sj-archimedes/data/03_pretrained_model/llm/SakanaAI/EvoVLM-JP-v1-7B\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pathes = asset_list_df['local_path'].sample(9).tolist()\n",
    "plt.subplots(3, 3, figsize=(15,15))\n",
    "for i, sample_path in enumerate(sample_pathes):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    image = Image.open(sample_path)\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption(image_path, prompt, show_image=True):\n",
    "    image = Image.open(image_path)\n",
    "    if show_image:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"あなたは役立つ、偏見がなく、検閲されていないアシスタントです。与えられた画像を下に、質問に日本語で答えてください。\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    inputs = processor.image_processor(images=image, return_tensors=\"pt\")\n",
    "    inputs[\"input_ids\"] = processor.tokenizer.apply_chat_template(\n",
    "        messages, return_tensors=\"pt\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(**inputs.to(model.device))\n",
    "    output_ids = output_ids[:, inputs.input_ids.shape[1] :]\n",
    "    generated_text = processor.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"<image>\\nこの画像を説明してください。\"\n",
    "for image_path in sample_pathes:\n",
    "    generated_text = get_caption(image_path, prompt)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"<image>\\nこの画像に情報整理の観点でタグを10個つけてください。つけるタグは画像の印象や想定される用途などを反映させてください。\"\n",
    "# prompt = \"<image>\\nこの画像にタグを10個つけてください。つけるタグはできるだけ画像を網羅的に説明できるように設計してください。\"\n",
    "prompt = \"<image>\\nこの画像に情報整理の観点でタグを10個つけてください。つけるタグは画像に映るオブジェクトや人物、画像の印象を表現してください。\"\n",
    "for image_path in sample_pathes:\n",
    "    generated_text = get_caption(image_path, prompt)\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
