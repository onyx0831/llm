{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb765d89-dd4a-4d85-8ec0-0b6f7cb69181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "lap_df = pd.read_pickle('/media/sj-archimedes/data/share/OddAI_Library_practice/data08/lap_trainval_20221001-20231031.pkl')\n",
    "lap_df = lap_df.query('creative_type == \"image\"')\n",
    "lap_df['creative_media_url'] = lap_df['creative_media_url'].map(lambda x: x[0])\n",
    "lap_df['creative_media_hash'] = lap_df['creative_media_hash'].map(lambda x: x[0])\n",
    "\n",
    "fba_df = pd.read_pickle('/media/sj-archimedes/data/share/OddAI_Library_practice/data08/fba_trainval_20221001-20231031.pkl')\n",
    "fba_df = fba_df.query('creative_type == \"image\"')\n",
    "fba_df['creative_media_url'] = fba_df['creative_media_url'].map(lambda x: x[0])\n",
    "fba_df['creative_media_hash'] = fba_df['creative_media_hash'].map(lambda x: x[0])\n",
    "\n",
    "df = pd.concat([lap_df, fba_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328807de-cb92-4090-95ee-0bd35b141ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_caption_dict = {}\n",
    "\n",
    "caption_dict_list = glob('./output/*.pkl')\n",
    "caption_dict = {}\n",
    "for fname in caption_dict_list:\n",
    "    with open(fname, 'rb') as r:\n",
    "        caption_dict |= pickle.load(r)\n",
    "all_caption_dict['caption'] = caption_dict\n",
    "\n",
    "appeal_dict_list = glob('./output_appeal_caption/*.pkl')\n",
    "\n",
    "appeal_dict = {}\n",
    "for fname in appeal_dict_list:\n",
    "    with open(fname, 'rb') as r:\n",
    "        appeal_dict |= pickle.load(r)\n",
    "\n",
    "all_caption_dict['appeal'] = appeal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168a8f7-bae6-4b46-8db5-f949c68bccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caption'] = df['creative_media_hash'].map(\n",
    "    lambda x: all_caption_dict['caption'][x] if x in all_caption_dict['caption'] else None\n",
    ")\n",
    "df['appeal'] = df['creative_media_hash'].map(\n",
    "    lambda x: all_caption_dict['appeal'][x] if x in all_caption_dict['appeal'] else None\n",
    ")\n",
    "df = df[~df['appeal'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd9e4a-b0ea-4ec6-83ed-81bc2ff5385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['creative_media_hash', 'creative_media_url', 'caption', 'appeal']]\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a70b7-412e-4008-a912-8d35cffbde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cadb9b9-f09c-4c47-adf8-91455276641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "ctx_encoder.to('cuda:2')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061aded-eb85-4553-abaa-99f80cab8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda example: {'embeddings_caption': ctx_encoder(**ctx_tokenizer(example[\"caption\"], return_tensors=\"pt\", max_length=512).to('cuda:2'))[0][0].cpu().numpy()}\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda example: {'embeddings_appeal': ctx_encoder(**ctx_tokenizer(example[\"appeal\"], return_tensors=\"pt\", max_length=512).to('cuda:2'))[0][0].cpu().numpy()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8eb8d8-e469-4fd6-b2ca-adc783ce798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "dataset.add_faiss_index(column='embeddings_caption')\n",
    "dataset.add_faiss_index(column='embeddings_appeal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6c37b-4bea-4f0d-b198-b631b5ad9753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "q_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa21cb-c723-4ce0-9d15-61dd99abcbf3",
   "metadata": {},
   "source": [
    "# 広告画像をqueryとする\n",
    "実際にはその広告画像のcaptionやappeal captionをqueryとしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbce94-cfdd-4ca8-8bd7-6cdd68b8e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from src.utils import download_image_from_s3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = random.randint(0, 6241)\n",
    "\n",
    "query_ds = dataset[idx]\n",
    "img = download_image_from_s3(query_ds['creative_media_url'])\n",
    "print('===== caption =====')\n",
    "print(query_ds['caption'])\n",
    "print('\\n===== appeal =====')\n",
    "print(query_ds['appeal'])\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56517513-e53d-4cea-af6c-8746feb78c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from src.utils import download_image_from_s3\n",
    "import matplotlib.pyplot as plt\n",
    "# openai.api_key = ''\n",
    "\n",
    "# query = f\"次の文章を英語に翻訳してください。\\n{query}\"\n",
    "\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "# query = client.chat.completions.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": query},\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# query = query.choices[0].message.content\n",
    "\n",
    "query = query_ds['caption']\n",
    "print(query)\n",
    "question_embedding = q_encoder(**q_tokenizer(query, return_tensors=\"pt\"))[0][0].numpy()\n",
    "caption_scores, caption_retrieved_examples = dataset.get_nearest_examples('embeddings_caption', question_embedding, k=10)\n",
    "\n",
    "query = query_ds['appeal']\n",
    "print(query)\n",
    "question_embedding = q_encoder(**q_tokenizer(query, return_tensors=\"pt\"))[0][0].numpy()\n",
    "appeal_scores, appeal_retrieved_examples = dataset.get_nearest_examples('embeddings_appeal', question_embedding, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d854c-e060-4452-81d3-6eff91906d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_hashes = caption_retrieved_examples['creative_media_hash']\n",
    "s3_urls = caption_retrieved_examples['creative_media_url']\n",
    "captions = caption_retrieved_examples['caption']\n",
    "\n",
    "for url, caption in zip(s3_urls, captions):\n",
    "    print(caption)\n",
    "    img = download_image_from_s3(url)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('\\n==============\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28133462-4002-406e-b50b-a58a74f977a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_hashes = appeal_retrieved_examples['creative_media_hash']\n",
    "s3_urls = appeal_retrieved_examples['creative_media_url']\n",
    "captions = appeal_retrieved_examples['caption']\n",
    "\n",
    "for url, caption in zip(s3_urls, captions):\n",
    "    print(caption)\n",
    "    img = download_image_from_s3(url)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('\\n==============\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465282c5-40da-4796-b752-702bfb105f3f",
   "metadata": {},
   "source": [
    "# ユーザが自然言語で検索する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de2fb8-56a4-4d20-8f54-0973512add05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from src.utils import download_image_from_s3\n",
    "import matplotlib.pyplot as plt\n",
    "openai.api_key = ''\n",
    "\n",
    "\n",
    "query = \"声優、限定\"\n",
    "query = f\"次の文章を英語に翻訳してください。\\n{query}\"\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "query = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": query},\n",
    "  ]\n",
    ")\n",
    "\n",
    "query = query.choices[0].message.content\n",
    "\n",
    "print(query)\n",
    "question_embedding = q_encoder(**q_tokenizer(query, return_tensors=\"pt\"))[0][0].numpy()\n",
    "caption_scores, caption_retrieved_examples = dataset.get_nearest_examples('embeddings_caption', question_embedding, k=10)\n",
    "appeal_scores, appeal_retrieved_examples = dataset.get_nearest_examples('embeddings_appeal', question_embedding, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b34d5-b0e2-41d1-b985-7702586d000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_hashes = caption_retrieved_examples['creative_media_hash']\n",
    "s3_urls = caption_retrieved_examples['creative_media_url']\n",
    "captions = caption_retrieved_examples['caption']\n",
    "\n",
    "for url, caption in zip(s3_urls, captions):\n",
    "    print(caption)\n",
    "    img = download_image_from_s3(url)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('\\n==============\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e37c23-5fa3-450a-a095-368c7c5fd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_hashes = appeal_retrieved_examples['creative_media_hash']\n",
    "s3_urls = appeal_retrieved_examples['creative_media_url']\n",
    "captions = appeal_retrieved_examples['caption']\n",
    "\n",
    "for url, caption in zip(s3_urls, captions):\n",
    "    print(caption)\n",
    "    img = download_image_from_s3(url)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('\\n==============\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33bf6b-1ecf-43b1-889e-470b2c49629b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
